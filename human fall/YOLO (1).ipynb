{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYX53PjpZldh"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "FuX3iTkjrimG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cvzone"
      ],
      "metadata": {
        "id": "oAyPgs-Crkrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Define directories for multiple folders\n",
        "base_dirs = [\n",
        "    '/content/drive/MyDrive/data_set1/data_set1/Coffee/Annotations_files',\n",
        "    '/content/drive/MyDrive/data_set1/data_set1/Coffee/Video',\n",
        "    '/content/drive/MyDrive/data_set1/data_set1/Home/Annotations_files',\n",
        "    '/content/drive/MyDrive/data_set1/data_set1/Home/Video'\n",
        "]\n",
        "\n",
        "# Output directory in Google Drive\n",
        "output_base_dir = '/content/drive/MyDrive/Fall_detectionp'  # Main output directory in Google Drive\n",
        "fall_dir = os.path.join(output_base_dir, 'Fall')\n",
        "non_fall_dir = os.path.join(output_base_dir, 'Non_Fall')\n",
        "\n",
        "# Create the directories for Fall and Non-Fall if they don't exist\n",
        "os.makedirs(fall_dir, exist_ok=True)\n",
        "os.makedirs(non_fall_dir, exist_ok=True)\n",
        "\n",
        "# Initialize a list to hold the frame filenames, labels, and bounding box coordinates\n",
        "data = []\n",
        "\n",
        "# Confidence threshold for detection\n",
        "confidence_threshold = 0.5\n",
        "\n",
        "# Aspect ratio threshold for fall detection\n",
        "aspect_ratio_threshold = 1  # Updated to 1.5 for better classification\n",
        "\n",
        "# Process videos\n",
        "for base_dir in base_dirs:\n",
        "    video_files = [f for f in os.listdir(base_dir) if f.endswith('.avi')]\n",
        "\n",
        "    print(f\"Found video files in {base_dir}: {video_files}\")\n",
        "\n",
        "    for video_file in video_files:\n",
        "        video_path = os.path.join(base_dir, video_file)\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_counter = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_counter += 1  # Increment frame counter for every frame processed\n",
        "\n",
        "            # Detect objects using the YOLO model\n",
        "            results = model(frame)\n",
        "            results = results[0]\n",
        "\n",
        "            detected = False\n",
        "            for box in results.boxes:\n",
        "                # Extract bounding box coordinates and dimensions\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = box.conf[0].item()  # Confidence score\n",
        "                cls = int(box.cls[0].item())  # Class ID (0 = person)\n",
        "\n",
        "                # Process only if the detected class is 'person' and confidence is high enough\n",
        "                if cls == 0 and conf > confidence_threshold:\n",
        "                    detected = True\n",
        "\n",
        "                    # Compute bounding box dimensions\n",
        "                    width = x2 - x1\n",
        "                    height = y2 - y1\n",
        "\n",
        "                    # Debugging: Print dimensions and aspect ratio\n",
        "                    print(f\"Frame {frame_counter}: Detected 'person' with confidence {conf:.2f}\")\n",
        "                    print(f\"Bounding Box: x1={x1}, y1={y1}, x2={x2}, y2={y2}, Width={width}, Height={height}\")\n",
        "\n",
        "                    # Calculate the aspect ratio\n",
        "                    aspect_ratio = height / width\n",
        "                    print(f\"Aspect Ratio: {aspect_ratio:.2f} (Threshold: {aspect_ratio_threshold})\")\n",
        "\n",
        "                    # Classify Fall vs. Non-Fall based on aspect ratio\n",
        "                    if aspect_ratio < aspect_ratio_threshold:  # Fall condition\n",
        "                        label = 'Fall'\n",
        "                        color = (0, 0, 255)  # Red for Fall\n",
        "                        save_dir = fall_dir\n",
        "                    else:  # Non-Fall condition\n",
        "                        label = 'Non-Fall'\n",
        "                        color = (0, 255, 0)  # Green for Non-Fall\n",
        "                        save_dir = non_fall_dir\n",
        "\n",
        "                    # Draw bounding box and label\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "                    text = f\"{label} ({conf:.2f})\"\n",
        "                    cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "                    # Save the frame\n",
        "                    frame_filename = os.path.join(save_dir, f\"{video_file}_frame_{frame_counter:04d}_{label}.jpg\")\n",
        "                    cv2.imwrite(frame_filename, frame)\n",
        "\n",
        "                    # Append to data (add bounding box coordinates)\n",
        "                    data.append([frame_filename, label, x1, y1, x2, y2])\n",
        "                    print(f\"Saved {label} frame: {frame_filename}\")\n",
        "                    break  # Process only one bounding box per frame\n",
        "\n",
        "            # Display the frame (for visual debugging in Colab)\n",
        "            cv2_imshow(frame)\n",
        "\n",
        "            # Break loop for testing (remove this for full processing)\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "# Save the results to a CSV file\n",
        "labels_df = pd.DataFrame(data, columns=['image_path', 'label', 'x1', 'y1', 'x2', 'y2'])\n",
        "labels_df.to_csv(os.path.join(output_base_dir, 'labels.csv'), index=False)\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "PQ0DJIBIrmHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "egAQcnPn4_Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y-ZZbN-UxPd_"
      }
    }
  ]
}